\section{Dependency Information}

No representation of trait ability mentioned so far specifically accounts for
dependency relationships between questions.  There are certainly dependency
relationships between whole (Bloom $\times$ concept) catogories.  For example,
one must be able to execute a for-loop (Comprehension of Loops) well before
gaining the ability to write one which satisfies an intended goal (Synthesis of
Loops). This is a course-grained dependency.

Other course-grained dependencies might be less obvious; questions in
categories for which concept is high-level and Bloom is low-level, depending on
questions in categories for which concept is lower-level and Bloom is
high-level.  For example, understanding a for-loop (Comprehension of Loops) is
predicated on being able to evaluate expressions (Application of Expressions).
In a trait ability matrix, these categories might even lie on a diagonal, which
would otherwise seem to suggest their independence.

Consider finer-grained dependency relationships among the following specific
questions regarding expressions:

\begin{verbatim}
 (a) What is (5 % 2)?
 (b) What is (5 / 2)?
 (c) What is (5 % (5 / 2))?
\end{verbatim}

The intuition captured by this example is that Part (c) could not be answered
correctly, at least not by any logical chain of reasoning, without possessing
the specific application ability that Part (a) and Part (b) test for.

It is probably true that Part (c) is more difficult than Part (a) or Part (b),
but this is not the reason for the dependency; rather it would appear the
dependency is the reason for the higher difficulty.  In terms of questions
which test application ability for expressions, all of the questions are in the
same neighborhood of difficulty; it is even possible albeit unlikely for the
$\beta$ values for all of these to be equal.  

However, if dependencies of the form $c \rightarrow a$ and $c \rightarrow b$
exist (that is, $c$ depends on $a$ and $b$), they would be indicated by high
binary correlations between $c$ and $a$ and $c$ and $b$.

% TODO: definitions

Even more telling than the coefficients of determination are the loadings from
a confirmatory factor analysis, which when squared give the proportions of
variance attributable to $a$ and $b$.  This technique gives an indication of
the degree to which $c$ depends on $a$ and $b$, and the relative proportions of
this dependency.

% TODO: definitions

\subsection{Probability Estimates Using Dependees}

Consider the vector of squared factor loadings for a set of content items,
where the depender is a content item $j$.  Suppose these content items are
independent.

\begin{equation}
 \begin{array}{llll}
  \Lambda = \Big[ \lambda_1^2 & \lambda_2^2 & \ldots & \lambda_n^2 \Big]
 \end{array}
\end{equation}

The total amount of explained variance is given by:

\begin{equation}
 \begin{array}{llll}
  E = \displaystyle\sum_{i=1}^n \lambda_i^2
 \end{array}
\end{equation}

And the unexplained variance by:

\begin{equation}
 \begin{array}{llll}
  U = 1 - E.
 \end{array}
\end{equation}

Suppose a student gives a unique one-time response to each question, thereby 
producing a response set vector:

\begin{equation}
 \begin{array}{llll}
  X = \Big[ x_1 & x_2 & \ldots & x_n \Big]
 \end{array}
\end{equation}

The regression model used to obtain the probability that the student answers
the depender question correctly is:

\begin{equation}
 \begin{array}{llll}
  p_j =  x_1\lambda_1^2 + x_2\lambda_2^2 + \ldots + x_n\lambda_n^2 + U\epsilon
 \end{array}
\end{equation}

Alternatively:

\begin{equation}
 \begin{array}{llll}
  p_j =  \displaystyle\sum x_i\lambda_i^2 + U\epsilon
 \end{array}
\end{equation}

where $\epsilon$ is some error function not accounted for by the dependencies,
having range $0 \leq \epsilon \leq 1$.  It accounts for factors not explained
in the confirmatory factor analysis which nevertheless influence the test;
these could be the student's intelligence, aptitude for that particular
problem, or how many hours of sleep were had the night before; or other,
inconceivable factors.

The proceeding assumption is that the unexplained variance is due to item
discrimination, problem difficulty, and trait ability.  That is:

\begin{equation}
 \begin{array}{llll}
  \epsilon = \gamma_j + \frac{1}{1 + e^{\alpha_j (\theta_s^{*} - \beta_j)}},
 \end{array}
\end{equation}

which is to say that the remainder of the probability can be estimated using
Item Response Theory and what is known about the student's trait ability from
other problems which, while not strictly dependencies, inform the probability
that a student will be able to answer a question of this nature.  A caveat is
that the $\theta_s$ used in this calculation should not include any of the
depenedencies in its MLE, since they are accounted for in the formula.  This
value is denoted as $\theta_s^{*}$

And therefore the estimated probability is:

\begin{equation}
 \begin{array}{llll}
  p_j =  \displaystyle\sum x_i\lambda_i^2 + U \Bigg[ \gamma_j + \frac{1}{1 + e^{\alpha_j (\theta_s^{*} - \beta_j)}} \Bigg].
 \end{array}
\end{equation}

This assumes, however, an atemporal view.  It assumes a scenario in which
memory is flawless; that all of the dependencies reside in memory at the time
of the asking of the target (depender) question.  Also, it assumes that there
is no feedback given for incorrect responses to questions. 

Rather than a response $x_i$, instead a probability $p_i$ can be modeled by
a combination of Item Response Theory and theories of memory and forgetting.
In that case:

\begin{equation}
 \begin{array}{llll}
  p_j(t) =  \displaystyle\sum p_i(t)\lambda_i^2 + U \Bigg[ \gamma_j + \frac{1}{1 + e^{\alpha_j (\theta_s^{*} - \beta_j)}} \Bigg].
 \end{array}
\end{equation}

That is, the probability of answering a target question correctly is the
product of the probabilities of answering the dependencies correctly by the
proportions of variance explained by the dependencies, plus the remainder of
variance explained by Item Response Theory: the item parameters and the
student's trait ability.  

What remains is a temporal account of questions, in particular the role of
memory and forgetting.
