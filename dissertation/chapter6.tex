\section{Item Scheduling}

The general procedure for scheduling content and assessments can be stated as
follows.  First, the trait ability matrix for the student is initialized:

\begin{equation}
  \Theta \leftarrow -\infty
\end{equation}

That is, the algorithm initially proceeds on the assumption that it is not
possible for any student to answer any question with probability greater than
zero.  In the first iteration, schedule a preliminary test consisting of a
diagonal block of the trait ability matrix, for example:

\begin{equation}
\Theta_s =\left[
         \begin{array}{llll}
              \y\theta_{s11} & \y\theta_{s21} & \y\theta_{s31} & \ldots \\
              \y\theta_{s12} & \y\theta_{s22} &                 &        \\
              \y\theta_{s13} &                 & \ddots          &        \\
              \vdots          &                 &                 &        \\
         \end{array}
       \right]
\end{equation}

The test should be small enough to be feasible while having enough questions to
support an MLE.  At least two questions are needed per (Bloom $\times$ concept)
for an MLE.  A 3 $\times$ 3 or triangle is sufficient.

Once the data is collected, it is then possible to calculate $\alpha_i$ and
$\beta_i$ for all items. 

With respect to $\alpha_i$, it is desirable to discard any question $i$ for
which $\alpha_i < 0$.  Recall that negative values of $\alpha$ indicate a
negative biserial correlation with the composite score, which means that the
question asked is an indicator of whether or not the student will perform
poorly on the overall measure.  

It $\alpha_i$ is close to -1, then the question may have powerful predictive
power, in which case it should be analyzed for its properties.  It may be
desirable to retain such questions for the purpose of predicting success.
Regardless, if $\alpha_i < 0$, then it along with its subtree should be severed
from the dependency graph, and should only be asked independently as part
of a preliminary testing measure.

With the response set, $\Theta_s$ can be constructed and the proximal zone of
development can be identified, as well as a distribution to select the category
from.  

Once a category is selected, the roots of the assessment tree are traversed
until either a question within the neighborhood of the trait ability is found,
or if no question is found, the traversal ends and another random category is
selected.

\subsection{Finding High-Impact Items}

Once a node on the tree is found, a check is performed to ensure the
dependencies have been asked.  If not, an in-order recursive descent is done on
each dependency, and this procedure is performed on the sub-dependencies.  If
all dependencies have been asked, the probability of the target question is
evaluated.  If the probability is .5, the question is asked. 

If the probability is less than .5, a confirmatory factor analysis is performed
on the dependencies of the node.  At any time, this factor analysis may reveal
a squared loading near zero, which indicates that the dependency relationship
indicated by the graph is not an actual dependency.  In that event, the link
between the target and the ``dependency`` is severed and a confirmatory factor
analysis is re-run on the remaining dependencies.

The most impactful dependency is sought.  This dependency item $i$ is selected
as follows: 

\begin{equation}
  \underset{i}{\mathrm{argmax}} \Bigg[ (1 - p_i) \lambda_i^2 \Bigg]
\end{equation}

The value $\lambda^2$ is the proportion of variance due to that dependency, so
it is preferred to start with higher proportions of variance.  Also $(1-p_i)$
is the room for improvement in the probability of the answering the dependency
correctly.  The intuition is that the more likely it is that the student is
able to answer the dependency correctly, the probability of answering the
target question rises---to the extent of the dependency relationship. 

\subsection{Finding the Next Item}

The maximal value for $(1 - p_i) \lambda_i^2$ may have $p_i < .5$, in which
case the above procedure is recursively applied to the dependencies with
$i$ as the target question.  

Eventually, the algorithm will converge on either a question for which $p_i >
.5$, or it will hit the leaves.  What this means is that there is no question
in the sub-tree for which $p_i$

\subsection{Finding the Whole Schedule}

