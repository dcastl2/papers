\section{Item Scheduling}
\label{sec:scheduler}

The general procedure for scheduling content and assessments can be stated as
follows.  

\subsection{Preliminaries}

First, at the very beginning of the program, the trait ability matrix
for the student is initialized:

\begin{equations}
  \Theta \leftarrow -3
\end{equations}

That is, the algorithm initially proceeds on the assumption that it is unlikely
for any student to answer any question.  The initial estimate for the $\alpha$
values may be 1, such that the Item Response Theory 3PL model defaults to 2PL
in the absence of any data.  The initial difficulty estimates may be determined
by the instructor, or they may be initialized set to 0.  The $\mu$ values may
be initialized to 1.

The first iteration schedules a preliminary test consisting of a diagonal block
of the trait ability matrix, for example:

\begin{equations}
\Theta_s =\left[
         \begin{array}{llll}
              \y\theta_{s11} & \y\theta_{s21} & \y\theta_{s31} & \ldots \\
              \y\theta_{s12} & \y\theta_{s22} &                &        \\
              \y\theta_{s13} &                & \ddots          &        \\
              \vdots         &                &                 &        \\
         \end{array}
       \right]
\end{equations}

The test should be small enough to be feasible while having enough questions to
support an MLE.  At least two questions are needed per (Bloom $\times$ concept)
for an MLE.  Asking the questions from a single catetegory is sufficient to
jumpstart the process, but the larger the triangle, the richer the initial
information ($\alpha$, $\beta$ values).  Once the data is collected, it is then
possible to re-calculate $\alpha_i$ and $\beta_i$ for all items. 

With respect to $\alpha_i$, it is desirable to discard any question $i$ for
which $\alpha_i \leq 0$.  Recall that negative values of $\alpha$ indicate a
negative biserial correlation with the composite score, which means that the
question asked is an indicator of whether or not the student will perform
poorly on the overall measure.  

If $\alpha_i$ is close to -1, then the question may have predictive power, in
which case it should be analyzed for its properties.  It may be desirable to
retain such questions for the purpose of predicting success.  Regardless, if
$\alpha_i < 0$, then it along with its subtree should be severed from the
dependency graph.

With the response set, $\Theta_s$ can be constructed and the proximal zone of
development can be identified.

\subsection{Subsequent Assessments}

When a student is assigned an assessment, first the probabilities that the
student will be able to answer each question are recursively calculated.  They
must be calculated from the bottom-up, since internal nodes require probability
estimates from their children.  The leaves are the only nodes that do not
require logistic regression to obtain a probability estimate, since the leaves
have no dependencies.  Probability estimates for the children are obtained
using Item Response Theory.

For each node which has been answered, the probability of recall can be
calculated using Eq~\ref{eq:memory}.  In the presence of a probability of
recall, the final probability of answering the question can be calculated
using Eq~\ref{eq:p-final}.  

Then, a recursive traversal beings at the root of each tree.  If the
probability of answering the question at the root is within the neighborhood of
[$\delta$, .5+$\delta$], it is asked.  Recall that low probabilities correspond
to higher differences in $\beta-\theta$; thus if a probability is very low, yet
the student answers the question correctly, it will indicate a corresponding
rise in trait ability.  Such items have higher impact on the MLE estimate of
trait ability.  Yet if the probability is below .5, there is no reasonable
assurance the student will be able to answer it to begin with.

If the probability to answer the question correctly is in the neighborhood of
[.5+$\delta$, 1],  the question is skipped.  The algorithm may recursively
descend into its dependencies to find lower-$p$ items.

If the probability is less than .5, then the system will seek to raise the
probability by targetting the dependees, in order of the highest-impact
dependees to the lowest-impact.

\subsection{Finding High-Impact Items}

The dependee which controls the highest amount of variance in the parent
probability is that dependee which has the highest coefficient in the logistic
regression model.  However the student may already have a high probability of
answering that dependee, such that there is little room for increases in the
probability in the parent node due to answering the child node question
correctly.

Supposing $p_i$ is the probability of answering the ith dependee correctly,
then the amount which can be gained in the dependee is

\begin{equations}
  \Delta_i = 1 - p_i
\end{equations}

If $\Delta_i$ assumes a value close to zero, it implies two things: first,
the student's trait ability for the dependee is high enough not to bother
testing it, and second, raising it to 1 would likely have little effect on
the probability estimate of the parent. 

Thus the highest impact item is determined not only by the coefficient, but
also by the gain in probability for the dependee.  Supposing that the odds
estimate for the parent $j$ were given by

\begin{equations}
  logit_j = e^{b_1 p_1 + b_2 p_2 + \ldots b_i p_i \ldots b_n p_n}
\end{equations}

Then the odds estimate for the parent $j$ if the probability were to rise
to 1 would be

\begin{equations}
  logit_j = e^{b_1 p_1 + b_2 p_2 + \ldots b_i p_i  + b_i \ldots b_n p_n}
\end{equations}

then the odds ratio would be equal to 

\begin{equations}
  \frac{ 
    e^{b_1 p_1 + b_2 p_2 + \ldots + b_i + \ldots b_n p_n} 
  } {
    e^{b_1 p_1 + b_2 p_2 + \ldots b_i p_i  + b_i p_i \ldots b_n p_n}
  }
\end{equations}

which when reduced is simply

\begin{equations}
    e^{b_i \Delta_i}
\end{equations}

Thus that dependency which has the highest increase in the odds ratio is
the item $i$ such that

\begin{equations}
  \underset{i}{\mathrm{argmax}} \Bigg[ \Big( e^{b_i} \Big)^{\Delta_i} \Bigg]
\end{equations}

If that dependency has a probability within the window [.5, .5+$\delta$], it is
asked; otherwise if it has probability [0, .5), the algorithm is recursively
applied to the dependency.

\subsection{Finding the Whole Schedule}

The above algorithm may find a complete schedule by iteratively finding the
next item in the schedule, then proceeding on the assumption that the item is
answered correctly and is re-activated.  In order to preserve the data in the
course of iteratively finding the next item, the student's trait ability matrix
and the student dependency graph may first be copied.  Any changes to trait
ability estimates or to the student's responses set are reflected in the
copies.

The algorithm comes to a stopping point when there exists no question for which
the probability of answering falls below .5+$\delta$.

